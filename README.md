# Titanic-Machine_Learning_Disaster-kaggle

It's a <b>Titanic: Machine Learning from Disaster - Start here! Predict survival on the Titanic and get familiar with ML basics</b> from *<a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener noreferrer">Kaggle</a>* 

So, If you think it's easy for beigner not at all but still good to start with it first. If you notice tag line "Start here! Predict survival on the Titanic and get familiar with <b>ML basics</b>". You will get famillier to basics of Machine Learning.

Concept will be same where as the code is avilable in Python and definately scope of improvement. I tried to comment and mantain code very well but sill if you have any query ping *<a href="https://www.linkedin.com/in/mrnikhilgupta/" target="_blank" rel="noopener noreferrer">me</a>*.

I have divided this problem three parts<br>
1. <b>Pre-processing</b><br>
   Import libraries<br>
   Import datasets<br>
   Feature engineering<br>
   Dataset cleaning<br>
   Dividibg dataset<br>
   Missing Numaric Data<br>
   Encode categorical/string/character data<br>
   Splitting dataset<br>
   Fetaure Scalling<br><br>
2. <b>Algo and Hypertunning</b><br>
   K Neighbors Classifier<br>
   SVM Classifier<br>
   kernel SVM Classifier<br>
   Decision Tree Classifier<br>
   Random Forest Classifier<br>
   XG Boost Classifier<br>
   k-Fold Cross Validation<br>
   Grid Search CV<br>
   ANN using Keras<br><br>
3. <b>Validation and Prediction</b><br>
   Predicting Testset<br>
   Confusion Matrix<br>
   Predicting new observations<br>
   
Download and install <a href="https://www.anaconda.com/download/" target="_blank" rel="noopener noreferrer">Anaconda</a>. It's optional if python is already setup in your environment although *Anaconda* is much easier to use.

Now, clone or download <b>titanic-ml-disaster</b> folder (It include's python files and datasets) and run the code in IPython Console in the same folder.

*Winner of this problem in my case - <b>Random Forest Classifier</b>.*

Confusion Matrix dataset to describe the performance of a classification model.<br>
<b></b>True Negative (TN) = 101<br>
<b></b>False Negative (FN) = 15<br>
<b></b>False Positive (FP) = 9<br>
<b></b>True Positive (TP) = 54<br>

Don't Be Afraid of Scary Math, it's simple and short.

<b>Accuracy</b> = (TN + TP) / (TN + FP + FN + TP) ~ 86.6<br>
<b>Precision</b> = TP / (FP + TP) ~ 85.7<br>
<b>Recall</b> = TP / (FN + TP) ~ 78.3<br>
<b>F1</b> = 2 ((Precision x Recall) / (Precision + Recall)) ~ 81.8<br>

*<a href="https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9" target="_blank" rel="noopener noreferrer">Accuracy, Precision, Recall or F1?</a>* 

*<a href="https://www.linkedin.com/in/mrnikhilgupta/" target="_blank">Nikhil Gupta</a>* 

